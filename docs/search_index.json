[["index.html", "Fitopatometría en R", " Fitopatometría en R Juan Edwards Objetivos Familiarizar al alumno con las herramientas (paquetes) del software R para diferentes análisis de epidemias de enfermedades de cultivos agrícolas. Destinatarios Ingenieros agrónomos, Licenciados en Biotecnología o Licenciados en Biología que demuestren conocimientos previos sobre uso y manejo de R y sobre conceptos básicos de Fitopatología. Motivación “Our ability to understand a phenomenon is proportional to our ability to measure it” — Lord Kelvin (1824-1907) “How can plant pathologists apply advanced statistical procedures or develop quantitative models based upon disease assessment data of unknown accuracy and precision?” — David Mackenzie, 1979 “Without quantification of disease, no studies in epidemiology, no assessment of crop losses, and no plant disease surveys and their applications would be possible” — Kranz, 1988 “The cornerstone of epidemic analysis” — Campbell and Neher, 1994 "],["0-data.html", "Datasets", " Datasets pacman::p_load(tidyverse, googlesheets4, janitor) gs4_auth(email = &quot;edwardsmolina@gmail.com&quot;) gs4_deauth() datasets &lt;- gs4_get(&quot;https://docs.google.com/spreadsheets/d/16FUAtd-u50sU2si0Ot7j9Ueou7qwlGt5t9NkAdKwlBM/edit?usp=sharing&quot;) olivo &lt;- read_sheet(datasets, sheet = &quot;olivo&quot;, guess_max = 10000, skip=0) soja &lt;- read_sheet(datasets, sheet = &quot;soja&quot;, guess_max = 10000, skip=0) canola &lt;- read_sheet(datasets, sheet = &quot;canola&quot;, guess_max = 10000, skip=0) %&gt;% janitor::clean_names() cebada &lt;- read_sheet(datasets, sheet = &quot;cebada&quot;, guess_max = 10000, skip=0) %&gt;% janitor::clean_names() poroto &lt;- read_sheet(datasets, sheet = &quot;poroto&quot;, guess_max = 10000, skip=0) save(olivo, soja, canola, cebada, poroto, file=&quot;data/data.RData&quot;) "],["1_1-metricas_basicas.html", "1 Métricas báscias 1.1 Incidencia 1.2 Prevalencia 1.3 Severidad Wide (sev y yield) a long Mapa de prevalencia", " 1 Métricas báscias Cargamos datos y paquetes library(tidyverse) load(&quot;data/data.RData&quot;) Olivo/bacteriosis — olivo %&gt;% view dataset formato “wide” (planilla de campo) con 30 columnas de sev por arbol individual [datos simulados] Re-estructuracion — Pasamos de formato wide a long para hacer operaciones por grupos. Ojo: No siempre debe hacerse este paso aunque nos habilita a group_by()+ summarise() # le pedimos que apile las columnas conteniendo a las plantas 1 a 30 # el nombre de las columnas las apile en una columna llamada “tree” # la observaciones de severidad las apile en una columna llamada sev # el producto de este re-arreglo se llamará “oli_long” olivo %&gt;% pivot_longer(cols = `1`:`30`, names_to = &quot;tree&quot;, values_to = &quot;sev&quot;) -&gt; oli_long Chequeamos cuántos árboles fueron evaluados en cada año/región/lote: oli_long Chequeamos cuantos arboles se evaluaron por campo oli_long %&gt;% group_by(year, loc, farm) %&gt;% summarise(n= sum(!is.na(sev))) %&gt;% pivot_wider(names_from=year, values_from = n) Imprimimos los 30 árboles de un mismo lote oli_long %&gt;% arrange(loc, year) %&gt;% print(n=30) 1.1 Incidencia (nivel lote - evolución interanual) Probamos el artilugio matemático que nos permitirá calcular la proporción de árboles enfermos muestra1 &lt;- c(0,1) mean(muestra1) muestra2 &lt;- c(0,0,0,0,1) mean(muestra2) muestra3 &lt;- c(1,1,1,1,1,1,1,1,0,0) mean(muestra3) Ahora si, aplicaremos el artilugio a nuestros datos. Tip: pueden ir seleccionando por lineas para ir probando el codigo antes de ejecutarlo por completo (seleccionar hasta antes de cada pipe, sino quedará abierta la sentencia) oli_long %&gt;% mutate(diseased = sev&gt;0) %&gt;% group_by(year, loc, farm) %&gt;% summarise(inc = mean(diseased, na.rm=TRUE)*100) %&gt;% ungroup %&gt;% arrange(loc, year) -&gt; oli_inc Damos print a “oli_inc” oli_inc Graficamos oli_inc (una de las posibilidades) oli_inc %&gt;% ggplot()+ # aes(x=factor(year), y=inc) + aes(x=factor(year), y=inc, color=factor(farm)) + geom_point() + # geom_line() + geom_line(aes(group=farm)) + facet_grid(. ~ loc) 1.2 Prevalencia Nivel región - evolución interanual oli_inc %&gt;% mutate(diseased_farm = inc&gt;0) %&gt;% group_by(year, loc) %&gt;% summarise(prev = mean(diseased_farm, na.rm=TRUE)*100) %&gt;% ungroup %&gt;% arrange(loc,year) -&gt; oli_prev oli_prev Plot de oli_prev oli_prev %&gt;% ggplot()+ aes(x=factor(year), y=prev, color=factor(loc)) + geom_point() + geom_line(aes(group=loc)) 1.3 Severidad Calculamos ambas severidades vistas en la introducción teórica NOTA: en el teórico la sev_cond daba “NaN” en aquellos casos en que todos los arboles tenian sev=0, y en el filtrado sev[which(sev &gt; 0)] el vector quedaba vacío. oli_long %&gt;% group_by(year, loc, farm) %&gt;% summarise( sev_media = mean(sev, na.rm=TRUE), sev_cond =mean(sev[which(sev &gt; 0)])) %&gt;% ungroup %&gt;% mutate_all(~replace(., is.nan(.), 0)) %&gt;% arrange(loc, year) -&gt; oli_sev oli_sev Print oli_sev oli_sev Plot oli_sev Aprovechamos a usar una función muy eficiente que puede resultar una gran aliada en nuestro trabajo cotidiano: stat_summary() oli_sev %&gt;% ggplot()+ aes(x=loc, y =sev_media)+ geom_point(alpha=.3)+ facet_wrap(&quot;year&quot;)+ stat_summary(fun = mean, geom = &quot;crossbar&quot;, col=&quot;blue&quot;)+ stat_summary(aes(label=..y.. %&gt;% round(1)), fun=mean, geom=&quot;text&quot;, size=4, vjust = -0.5) + scale_x_discrete(guide = guide_axis(n.dodge = 2)) Bonus 1 Wide (sev y yield) a long Soja es el típico dataset de un experimento de campo donde evaluamos severidad y rendimiento de las parcelas soja %&gt;% view Vemos que tiene el formato de planilla de campo (wide), en donde no repetimos el nombre de trat, sino que ubicamos los datos de cada rep en la misma linea soja %&gt;% pivot_longer( cols = matches(&quot;_&quot;), names_to = c(&quot;.value&quot;, &quot;bk&quot;), names_sep = &quot;_&quot;) -&gt; soja_long print soja_long soja_long Gráfico exploratorio de sev soja_long %&gt;% ggplot()+ aes(x=factor(fungic), y=sev)+ geom_boxplot(width=.2) + geom_point(aes(col=factor(bk))) Gráfico exploratorio de yield soja_long %&gt;% ggplot()+ aes(x=fungic, y=yield)+ geom_boxplot(width=.2) + geom_point(aes(col=factor(bk))) Ahora este dataset nos permitirá entrar al modelado unviaridado de severidad o rendimiento, o bien establecer relaciones entre ambas variables (correlación o regresión). Bonus 2 Mapa de prevalencia library(tidyverse) library(sf) theme_set(theme_bw()+ theme( panel.grid.major = element_line(color = gray(0.5), linetype = &quot;dashed&quot;, size = 0.05), panel.background = element_rect(fill = &quot;aliceblue&quot;), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), )) ARG2 &lt;- raster::getData(name = &quot;GADM&quot;, country = &quot;ARG&quot;, level = 2) %&gt;% st_as_sf() # https://datascience.blog.wzb.eu/2019/04/30/zooming-in-on-maps-with-sf-and-ggplot2/ BSAS &lt;- ARG2 %&gt;% filter(NAME_1 == &quot;Buenos Aires&quot;) Cortamos la region de nuestro interes SEBA &lt;- st_crop(BSAS, xmin = -60, xmax = -57, ymin = -39, ymax = -37) Cuantos partidos quedaron incluidos? SEBA %&gt;% as_tibble %&gt;% count(NAME_2) Quedaron incluidos 18 partidos: Simulamos un dataset de prevalencia para 4 años cancro &lt;- SEBA %&gt;% as_tibble %&gt;% mutate(preval_2015 = rnorm(n=18, mean=30, sd=10), preval_2016 = preval_2015*1.05 + rnorm(1, 3, 2) , preval_2017 = preval_2016*1.05 + rnorm(1, 3, 2), preval_2018 = preval_2017*1.05 + rnorm(1, 3, 2)) %&gt;% pivot_longer(preval_2015:preval_2018, names_to = &quot;anio&quot;, values_to = &quot;prevalencia&quot;, names_prefix = &quot;preval_&quot;) cancro SEBA_cancro &lt;- SEBA %&gt;% left_join(cancro, by= &quot;NAME_2&quot;) #%&gt;% SEBA_cancro %&gt;% ggplot() + geom_sf(data=SEBA)+ geom_sf(aes(fill=prevalencia))+ scale_fill_gradient2(midpoint = 35, low = &#39;green2&#39;, mid = &#39;yellow&#39;, high = &#39;red3&#39;, na.value = &#39;gray95&#39;)+ facet_wrap(&quot;anio&quot;)+ labs(title = &quot;Evolución de la prevalencia del cancro del tallo de girasol&quot;, x = NULL, y = NULL, fill = &quot;Prevalencia&quot;) ggsave(last_plot(), file = &quot;fig/prevalencia_cancro.png&quot;, w=6, h=4) "],["1_2-dsi.html", "2 DSI", " 2 DSI Disease severity index (Indice de severidad) Poroto/sclerotinia poroto Dataset de formato wide, que incluye 3 variables descriptivas y 4 variables respuesta. poroto %&gt;% mutate(diseased = rowSums(dplyr::select(., matches(&#39;1|2|3|4&#39;)))) %&gt;% mutate(inc = diseased/n*100) %&gt;% mutate(dsi_eq1 = (1*class_1+2*class_2+3*class_3+4*class_4)/(n*4) *100) %&gt;% mutate(dsi_eq2 = (1*class_1+2*class_2+3*class_3+4*class_4)/n) %&gt;% mutate(dsi_midpoint = (.13*class_1 +.375*class_2 + .625*class_3 + .875*class_4)/n*100)%&gt;% mutate_at(vars(trt, rep), as.factor) -&gt; poroto_dsi Print poroto_dsi Model fitting mod0 &lt;- lm(dsi_midpoint ~ trt, data = poroto_dsi) par(mfrow = c(1, 2)) plot(mod0, which = c(1,2)) layout(1) MASS::boxcox(mod0) locator() # plot(fitted(mod0), resid(mod0), xlab = &quot;Fitted&quot;, ylab = &quot;Residuals&quot;) # abline(h = 0, lty = 2, col = &quot;darkorange&quot;, lwd = 2) # plot(mod0, which = c(1)) mod1 &lt;- lm(sqrt(dsi_midpoint) ~ trt, data = poroto_dsi) par(mfrow = c(1, 2)) plot(mod1, which = c(1,2)) MASS::boxcox(mod1) bctran &lt;- make.tran(&quot;boxcox&quot;, 0.596) mod2 &lt;- with(bctran, lm(linkfun(dsi_midpoint) ~ trt, data = poroto_dsi)) par(mfrow = c(1, 2)) plot(mod2, which = c(1,2)) asin_tran &lt;- make.tran(&quot;asin.sqrt&quot;, 100) mod3 &lt;- with(asin_tran, lm(linkfun(dsi_midpoint) ~ trt, data = poroto_dsi) ) par(mfrow = c(1, 2)) plot(mod3, which = c(1,2)) emmeans(mod3, ~ trt, type = &quot;response&quot;) poroto_dsi_p = transform(poroto_dsi, p = (dsi_midpoint/100)) mod4 = lm(log(p/(1-p)) ~ trt, data = poroto_dsi_p) emmeans(mod4, ~trt, tran = &quot;logit&quot;, at = list(dsi_midpoint = 3:81), type = &quot;response&quot;) AIC(mod1, mod2, mod3, mod4) "],["1_3-auc.html", "3 AUC", " 3 AUC Area bajo la curva de progreso de la enfermedad Reproducción de: https://apsjournals.apsnet.org/doi/10.1094/PHYTOFR-11-20-0033-A # install.packages(&quot;pacman&quot;) pacman::p_load(tidyverse, epifitter) time = c(1,2,3,4) y = c(1,2,3,10) Area under the disease progress curve (AUDPC) - Absoluta audpc_1 &lt;- AUDPC(time = time, y = y, y_proportion = FALSE, type = &quot;absolute&quot;) audpc_1 Area under the disease progress stairs (AUDPS) - Absoluta audps_1 &lt;- AUDPS(time = time, y = y, y_proportion = FALSE, type = &quot;absolute&quot;) audps_1 AUC standarizada sAUDPC &lt;- audpc_1/(4-1) sAUDPC sAUDPS &lt;- audps_1 * (4-1) / ((4-1)*4) sAUDPS AUDPC relativa audpc_max &lt;- 10*(4-1) (rAUDPC &lt;- audpc_1/audpc_max) AUDPS relativa audps_max &lt;- 10*(4) (rAUDPC &lt;- audps_1/audps_max) Aplicación a un caso real load(&quot;data/data.RData&quot;) Dataset canola Experimento de canola conducido en Balcarce, donde fueron testeados 10 fungicidas (mas un control sin protección con fungicida) con 3 bloques en el cual se registró el progreso de la incidencia de manchas foliares de Phoma lingam a través del tiempo (tiempo térmico desde la detección de la primera mancha) canola %&gt;% janitor::tabyl(trt, bk) canola %&gt;% pivot_longer( cols= inc_15:inc_248, names_to = &quot;tt&quot;, values_to = &quot;inc&quot;, names_prefix = &quot;inc_&quot;)-&gt; can_long can_long can_long &lt;- can_long %&gt;% mutate_at(vars(tt), as.numeric) can_long can_long %&gt;% unite(&quot;par&quot;, trt, bk, remove = FALSE) %&gt;% ggplot()+ aes(x=tt, y=inc)+ geom_line()+ facet_wrap(&quot;par&quot;) Calcularemos un valor de AUC por parcela con auxilio de las funciones group_by y summarize can_long %&gt;% group_by(trt, bk) %&gt;% summarize(auc = AUDPC(time = tt, y = inc, y_proportion = FALSE, type = &quot;absolute&quot;)) -&gt; can_auc Chequeamos str del nuevo dataset, que entrara al modelado can_auc can_auc &lt;- can_auc %&gt;% mutate_at(vars(trt, bk), as.factor) can_auc %&gt;% ggplot()+ aes(y=auc,x=trt, col=bk)+ geom_point() Model fitting pacman::p_load(emmeans, multcomp, scales) mod_canola &lt;- lm(auc ~ trt + bk, data = can_auc) par(mfrow = c(1, 2)) plot(mod_canola, which = c(1,2)) MASS::boxcox(mod_canola) mod_canola1 &lt;- lm(log(auc) ~ trt + bk, data = can_auc) par(mfrow = c(2, 2)) plot(mod_canola, which = c(1,2)) plot(mod_canola1, which = c(1,2)) layout(1) MASS::boxcox(mod_canola1) Estimamos las medias ajustadas por el modelo em &lt;- emmeans(mod_canola1, ~trt, type = &quot;response&quot;) Hacemos las comparaciones multiples segun test de Tukey res &lt;- multcomp::cld(em, Letters = letters, alpha = .05, reversed = F) res plot(res, alpha =0.5) + geom_vline(xintercept = res %&gt;% filter(trt==1) %&gt;% pull(response), linetype = 2, col =&quot;gray50&quot;)+ geom_point(data = can_auc, aes(x = auc, y = trt), pch=21, position=position_dodge(width=1), size = 2) + geom_text(data = res, angle=90, vjust=-0.7, aes(x = response, y = trt, label = .group), size = 4)+ labs(x=&quot;AUC incidencia de maculas&quot;, y = &quot;Tratamiento&quot;) + scale_x_continuous(breaks=scales::pretty_breaks())+ theme_bw()+ coord_flip() "],["1_4-inductoras_de_senescencia.html", "4 Enfermedades que inducen senescencia", " 4 Enfermedades que inducen senescencia Ensayo de fungicidas en cebada (trt=15). DBCA con 4 rep. Evaluaciones de sev media a los 0, 9, 20 y 29 dias desde aplicado. Estimacion de AF activa (lo que no es senescencia) La senescencia no cuenta para ninguna enfermedad, ya que es imposible distinguir su causa. cebada Hacemos un cebada long solo con fines graficos, entonces no creamos cebada_long. cebada %&gt;% pivot_longer( cols = c(&quot;verdor&quot;, &quot;e1_sev&quot;, &quot;e2_sev&quot;), names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% mutate(var = factor(var), var = fct_relevel(var, &quot;verdor&quot;)) %&gt;% ggplot()+ aes(x=dias, y=val, col = var)+ facet_wrap(&quot;trt&quot;)+ geom_point(alpha=0.3) + stat_summary(fun=mean, geom=&quot;line&quot;, size=0.7, alpha=.5, aes(col=var, group=var)) + scale_color_manual( labels = c(&quot;AF&quot;, &quot;Sev mancha en red (%)&quot;, &quot;Sev escaldadura (%)&quot;), values = c(&quot;green&quot;, &quot;red&quot;, &quot;blue&quot;) ) + theme_bw()+ labs(title = &quot;Evolución área foliar&quot;, y = &quot;%&quot;, x = &quot;Días desde aplicado&quot;, col = &quot;&quot;) Ahora calculamos el AF sana (%), restando al AF activa, la severidad media de mancha en red y escaldadura. cebada &lt;- cebada %&gt;% mutate(af_sana = verdor - e1_sev - e2_sev) %&gt;% mutate(sev_tot = e1_sev + e2_sev) cebada Finalmente calculamos el AUC del AF sana (LAI) cebada %&gt;% group_by(trt, rep) %&gt;% summarize(auc = AUDPC(time = dias, y = af_sana, y_proportion = FALSE, type = &quot;absolute&quot;)) -&gt; cebada_auc cebada_auc &lt;- cebada_auc %&gt;% mutate_at(vars(trt, rep), as.factor) cebada_auc %&gt;% ggplot()+ aes(y=auc, x=trt, col=rep)+ geom_point() … continuamos con los pasos anteriores de can_auc "],["2_1-pliman.html", "5 Pliman", " 5 Pliman Reproduciremos el post de Open Plant Pathology escrito por Emerson del Ponte browseURL(&quot;https://openplantpathology.org/posts/2021-05-31-measuring-plant-disease-severity-using-the-pliman-r-package/&quot;) Noten que pliman requiere R version 4 y el paquete “EBImage” (este paso se hace una sola vez) # install.packages(&quot;BiocManager&quot;) # BiocManager::install(&quot;EBImage&quot;) Ahora si instalemos/activemos los paquetes requeridos para esta sesión: pacman::p_load(tidyverse, pliman, epiR) Indicar background (b), sano (h) y sintomatico (s) h &lt;- image_import(&quot;pliman/sbr_h.png&quot;) s &lt;- image_import(&quot;pliman/sbr_s.png&quot;) b &lt;- image_import(&quot;pliman/sbr_b.png&quot;) Pedimos que muestre cada imagen indicada anteriormente: image_combine(h, s, b, ncol = 3) Imagen individual Importamos una solo imagen img46 &lt;- image_import(&quot;pliman/originals/img46.png&quot;) image_combine(img46) Pedimos estimar %sintomático / %sano symptomatic_area(img = img46, img_healthy = h, img_symptoms = s, img_background = b, show_image = TRUE) Y ahora que se haga la magia con todas las imagenes contenidas en una carpeta! Múltiples imagenes pliman &lt;- symptomatic_area(img_pattern = &quot;img&quot;, dir_original = &quot;pliman/originals&quot; , dir_processed = &quot;pliman/processed&quot;, save_image = TRUE, img_healthy = h, img_symptoms = s, img_background = b, show_image = FALSE) WTF! pliman Cuán buenas son las estimaciones hechas con pliman?? Estas imagenes evaluadas con pliman fueron evaluadas anteriormente con el software Quant (de conocida precision) quant &lt;- tribble( ~sample, ~actual, &quot;img5&quot;, 75, &quot;img11&quot;, 24, &quot;img35&quot;, 52, &quot;img37&quot;, 38, &quot;img38&quot;, 17, &quot;img46&quot;, 7, &quot;img63&quot;, 2.5, &quot;img67&quot;, 0.25, &quot;img70&quot;, 67, &quot;img75&quot;, 10 ) Fusionamos los data frames pliman y quant dat &lt;- left_join(pliman, quant) dat Visualizamos la confrontacion de las mediciones por ambos métodos, en eje x el “standard gold”y en y el que estamos poniendo a prueba: dat %&gt;% ggplot(aes(actual, symptomatic))+ geom_point()+ ylim(0,100)+ xlim(0,100)+ geom_abline(slope = 1, intercept = 0)+ theme_bw()+ labs(x = &quot;Quant&quot;, y = &quot;pliman&quot;) Calculamos el coeficiente de correlacion de concordancia entre variables continuas de Lin’s (1989, 2000) del paquete “epiR” (llamado en el chunk de session setup) ccc &lt;- epi.ccc(dat$actual, dat$symptomatic) ccc ccc$rho.c que tul?? "],["2_2-sad.html", "6 SAD 6.1 Lin’s concordance 6.2 Interrater reliability", " 6 SAD sad_wide_raw &lt;- read_csv(here::here(&quot;sad&quot;, &quot;data&quot;, &quot;data-sad.csv&quot;)) sad_wide_raw %&gt;% separate(method, c(&quot;author&quot;,&quot;method&quot;), &quot;_&quot;) %&gt;% mutate_if(is.character, as.factor) %&gt;% mutate_at(vars(author, method), fct_rev) -&gt; sad_wide sad_wide We need to reshape this data frame to the tidy format, where all responses are in a single column which facilitates further work within the tidyverse. For this, we use the gather function and create the rater and the estimate variables to accomodate data from the multiple columns. We should indicate the columns to gather, which are 4 to 23 and this way the first three columns are kept as we want: method, leaf and actual severity. sad_wide %&gt;% pivot_longer(cols= 5:24, names_to = &quot;rater&quot;, values_to = &quot;estimate&quot;) %&gt;% mutate_at(vars(rater), as.numeric) -&gt; sad sad sad %&gt;% ggplot(aes(x= method, y = estimate - actual)) + facet_wrap(&quot;author&quot;)+ geom_boxplot() + geom_jitter(width=.1, alpha=.2) First the absolute value sad %&gt;% ggplot(aes(x=leaf, y=actual, color = method)) + facet_wrap(&quot;author&quot;)+ geom_line(aes(leaf, actual, color = &quot;actual&quot;),size = 1.5) + geom_point(aes(leaf, estimate), size = 1.5, alpha = 0.2) + geom_smooth(aes(leaf, estimate), se = F) + labs(y = &quot;Severity (%)&quot;, x = &quot;Leaf ordered by increasing severity (0.25 to 84%)&quot;) Error of the estimates sad %&gt;% ggplot(aes(x= leaf, y=estimate - actual, color = method)) + facet_wrap(&quot;author&quot;)+ geom_hline(yintercept = 0) + geom_point(aes(leaf, estimate - actual), size = 1.5, alpha = 0.2) + geom_smooth(aes(leaf, estimate - actual), se = F) + labs(y = &quot;Severity&quot;, x = &quot;Leaf ordered by increasing severity (0.25 to 84%)&quot;) Per rater sad %&gt;% ggplot(aes(leaf, actual, col = method)) + geom_point(aes(leaf, estimate), size = 1, alpha = 0.2) + geom_smooth(aes(leaf, estimate), se = F) + facet_wrap(~ author*rater) + labs(y = &quot;Value&quot;, x = &quot;Leaf&quot;) And now for the error of the estimates. sad %&gt;% ggplot(aes(leaf, estimate - actual, color = method)) + geom_hline(yintercept = 0) + geom_point(aes(leaf, estimate - actual), size = 0.5, alpha = 0.1) + geom_smooth(aes(leaf, estimate - actual), se = F) + facet_grid(author~ rater) + labs(y = &quot;Value&quot;, x = &quot;Leaf&quot;) In the plots above we showed the error of the estimates by leaf, and although we know that severity was incremental, we had no information on this values. Hence, we can make another plot with severity on the x axis and identify ranges of actual severity with higher errors and compare the two SADs. 6.1 Lin’s concordance pacman::p_load(purrr, broom, epiR,lme4, car, emmeans, multcomp) ?epi.ccc() Veamos como opera la función epi.ccc. Para ello tomemos el primer evaluador de todo el dataset: sad %&gt;% nest(data = c(leaf, actual, estimate)) %&gt;% slice(1) %&gt;% unnest(data) -&gt; rater_1 Ahora si, apliquemos la funcion para rater_1 epi.ccc(rater_1$actual, rater_1$estimate, ci = &quot;z-transform&quot;, conf.level = 0.95) Calculando las metricas de manera serial para todos los evaluadores ccc_func &lt;- function(.) { epi.ccc(.$actual, .$estimate, ci = &quot;z-transform&quot;, conf.level = 0.95) } sad %&gt;% nest(data = c(leaf, actual, estimate)) -&gt; nested_sad nested_sad nested_sad %&gt;% mutate(fit = map(data, ccc_func)) -&gt; metrics metrics metrics %&gt;% unnest(fit) %&gt;% rowwise %&gt;% mutate(fit = toString(unlist(fit))) %&gt;% group_by(author, method, rater) %&gt;% summarize(string = paste(fit, collapse = &quot;_&quot;)) %&gt;% separate(col = string, into = c(&quot;LCC&quot;, &quot;s_shift&quot;, &quot;l_shift&quot;, &quot;C_b&quot;), sep = &quot;_&quot;) %&gt;% separate(col = LCC, into = c(&quot;LCC&quot;, &quot;ccc.lower&quot;, &quot;ccc.upper&quot;), sep = &quot;,&quot;) %&gt;% mutate_at(vars(author, method, rater), as.factor) %&gt;% mutate_if(is.character, as.double) %&gt;% ungroup -&gt; metric_results# metric_results %&gt;% knitr::kable() metric_results %&gt;% group_by(author, method) %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE) %&gt;% # select(l_shift, s_shift, C_b, ) %&gt;% arrange(desc(LCC)) metric_old &lt;- metric_results %&gt;% filter(author == &quot;old&quot;) metric_new &lt;- metric_results %&gt;% filter(author == &quot;new&quot;) pc_old &lt;- lmer(LCC ~ method + (1 | rater), data = metric_old, REML = FALSE) means_pc_old &lt;- emmeans(pc_old, ~ method) res_pc_old &lt;- cld(means_pc_old, Letters=letters) res_pc_old pc_new &lt;- lmer(LCC ~ method + (1 | rater), data = metric_new, REML = FALSE) means_pc_new &lt;- emmeans(pc_new, ~ method) res_pc_new &lt;- cld(means_pc_new, Letters=letters) res_pc_new 6.2 Interrater reliability Two methods were used here. The overall concordance coefficient and the intra-class correlation coefficient. No aid old library(irr) sad %&gt;% filter(author==&quot;old&quot;) %&gt;% filter(method==&quot;noaid&quot;) -&gt; sad_noaid_old sad_noaid_old %&gt;% pivot_wider(names_from = rater, values_from = estimate) %&gt;% dplyr::select(5:23) %&gt;% data.matrix() -&gt; sad_noaid_old2 sad_occc_noaid_old &lt;- epi.occc(sad_noaid_old2, na.rm = FALSE, pairs = TRUE) sad_icc_noaid_old &lt;- icc(sad_noaid_old2, model = &quot;twoway&quot;, unit = &quot;single&quot;, type = &quot;consistency&quot;) sad_occc_noaid_old$occc sad_icc_noaid_old$value "]]
